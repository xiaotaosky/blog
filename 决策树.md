
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

## 决策树  

## 1、信息熵  

**信息**：在集合T中有多个类别$$C_1,C_2,...,C_p$$，如果x为类别$$C_i$$的概率为$$p(x_i)$$，那么认为x包含了的信息有  
<div align="center">$$I(x_i)=-log_2p(x_i)$$</div>   

**信息熵**：集合T中的元素包含的信息的期望定义为信息熵，即  
<div align="center">$$H(T) = - \sum p(x_i)log_2p(x_i)$$</div>    
在决策树中，如果信息熵越大，认为集合越不纯。  

**信息增益**：将集合T按照特征属性X划分成多个子集合$$T_1,T_2,...,T_k$$后，这些集合的加权信息熵为
<div align="center">$$H(T_X)=\sum \frac{\|T_i\|}{\|T\|}H(T_i)$$</div>   
其中$$\|T\|$$表示集合T的元素个数。信息增益定义为
<div align="center">$$IG(T,X)=H(T)-H(T_X)$$</div> 
信息增益越大，属性X划分效果越好。  
&emsp;&emsp;例如，集合T中有两类元素，且两类元素个数近似，那么H(T)包含信息多（T最不纯），如果某个属性刚好可以把集合T分成两个比较纯的子集合（即每个集合几乎只含有其中一类元素），那么这时加权信息熵就比较小，信息增益比较大，该属性可以做较好的划分。  

**信息增益率**：特征属性X将集合T划分成子集合$$T_1,T_2,...,T_k$$，X自身的信息熵为  
<div align="center">$$SI(X)=-\sum(\|T_i\|/\|T\|)log_2(\|T_i\|/\|T\|)$$</div>     
定义信息增益率为  
<div align="center">$$IGR(T,X)=IG(T,X)/SI(X)$$</div>     

##  2、Gini不纯度  


## 3、ID3算法  

&emsp;&emsp;集合T作为根节点，递归迭代，每次迭代过程中，计算每个没有被使用的特征属性对应的信息熵（或信息增益），选择最小的信息熵（或最大的信息增益）对于的特征属性，通过该属性划分集合，生成子集合（子节点），迭代结束直至：子节点所有元素都划分到正确的类别，或者没有可用的特征属性。  
&emsp;&emsp;ID3算法使用贪婪算法，每次寻找最大的信息增益。但是ID3容易过拟合（overfit），生成较大的决策树，并且，ID3不能处理连续性特征属性。  


## 4、C.5  
&emsp;&emsp;C4.5算法和ID3算法迭代过程一样，不同的是C4.5使用的信息增益率，而不是信息增益。ID3偏向于取取值比较多的特征属性，信息增益率可以消弱这种倾向。  
&emsp;&emsp;**C4.5对连续变量的处理**：首先，将连续变量的取值从小到大排列$${v_1,v_2,...,v_m}$$，如果$$v_i$$对应的样本的类别与$$v_{i+1}$$对应的样本的类别不同，那么，将$$v_i$$作为阈值（分成小于等于和大于该阈值的两个区间），进而将连续变量划分成离散区间。每个阈值都可以计算出一个信息增益，取最大者作为该属性的信息增益。  
&emsp;&emsp;**C4.5对未知值的处理**：用不包含未知值的样本计算IG(T,X)，然后修正为F*IG(T,X)，其中F为已知样本数/样本总数；计算SI(X)时，将该属性的未知值为一组新的取值；最总计算出IGR(T,X)。  

## 5、悲观剪枝法（Pessimistic Error Pruning, PEP）
&emsp;&emsp;为了防止过拟合，树不能太复杂，所以需要修剪决策树。修建决策树有两种方法，一种是预修剪，在生成决策树之前，将样本分区不划分得那么细，例如用$$\chi^2$$检验，如果两个相邻的分区没有显著的不同的分布，那么可以将这两个分区合并；还有一种是后修剪，构建树后，用某些准则以回溯的方法去除树的一些节点，例如，通过自下而上的遍历树节点，通过验证集合的样本比较删去子树与不删除子树的错误率，来确定是否需要真正删除子树。在C4.5中，采用悲观剪枝法（PEP）。 
&emsp;&emsp;对于某个节点，设总共有n个数据经过该节点，定义随机变量X为经过该节点分类错误的个数，于是X服从二项分布，设经过该节点的数据分类错误的概率为p，于是有$$X \sim B(n,p) $$。根据Possion定理（或中心极限定理）知，在大样本条件下，X的分布可以近似于正态分布，$$X \sim N(np,npq)$$。尽管如此，但X仍然不是正态分布，所以我们可以评估p的置信区间。  
&emsp;&emsp;设$$\hat p$$是经过该节点的错误分类的个数所占比例，由中心极限定理知，需要评估p的置信区间时，可以构造统计量  
<div align="center">$$\frac{\hat{p} - p}{S/\sqrt{n}} =\frac{\hat{p}-p}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}}\sim N(0,1)$$</div>   
于是在置信度$$\alpha$$下，p的置信范围为  
<div align="center">$$p<\hat{p} + z_{\frac{\alpha}{2}}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$</div>   
&emsp;&emsp;对于叶子节点t，设经过该节点的错误分类个数为$$\hat{n_t}$$，由于我们将原始的随机变量X近似为正态分布，根据连续性校正，我们将错误个数$$\hat{n_t}$$修正为$$\hat{n_t}+\frac{1}{2}$$，于是  
<div align="center">$$\hat{p_t} = \frac{\hat{n_t}+\frac{1}{2}}{n_t}$$</div>   
对于非叶子节点T，分类错误个数由子叶子结点的分类错误个数和$$\sum{\hat{n_i}}$$修正为$$\sum{(\hat{n_i}+\frac{1}{2})}$$，所以  
<div align="center">$$\hat{p_T} = \frac{\sum{(\hat{n_i}+\frac{1}{2})}}{\sum{n_i}}$$</div>   
&emsp;&emsp;如果叶子节点t可以替代其父节点T，那么$$\hat{p_t}$$应该在父节点T的错误分类概率$$p_T $$的置信区间内，即  
<div align="center">$$\hat{p_t}<\hat{p_T} + z_{\frac{\alpha}{2}}\sqrt{\frac{\hat{p_T}(1-\hat{p_T})}{n_T}}$$</div>  
    
>连续性校正（Continuity correction）  
&emsp;&emsp;设随机变量X服从二项分布，$$X \sim B(n,p) $$,那么对于由X定义的事件的概率有$$P(X \leq x) = P (X < x+1)$$，其中x可以取值为0,1,2,...,n。当样本足够大（np和npq均足够大），那么这个由X定义的事件概率可以近似为$$P(Y \leq x+\frac{1}{2})，其中Y \sim N(np,npq)$$  
&emsp;&emsp;在x基础上加上$$\frac{1}{2}$$就是对x的连续性校正。  
&emsp;&emsp;对Possion分布也有类似的校正，$$ P(X \leq x) = P (X < x+1) \approx P(Y \leq x+\frac{1}{2}) $$   

参考:https://en.wikipedia.org/wiki/Binomial_distribution
https://en.wikipedia.org/wiki/Continuity_correction



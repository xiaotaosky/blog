<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

# 概率论基础

## 概率空间  
概率空间$$（\Omega,\mathcal{F},P）$$是一个总测度为1的测度空间，$$P（\Omega）=1$$。
>1.非空集合$$\Omega$$的元素称为样本，记作$$\omega$$。  
2.$$\mathcal{F}$$是$$\Omega$$的幂集的非空子集，且是一个$$\sigma-$$代数；其元素被称为事件。$$（\Omega,\mathcal{F}）$$是一个可测空间。  
3.P是概率，是$$\mathcal{F}$$到[0,1]上的一个测度，且$$P（\Omega）=1$$。  

举个例子，$$\Omega=\{\omega_1,\omega_2\}$$，$$\mathcal{F}$$是$$\Omega$$的幂集，概率P取值如下：  
&nbsp;&nbsp;&nbsp;&nbsp;$$P(\phi) = 0$$，$$P(\{\omega_1\}) = 0.5$$，  
&nbsp;&nbsp;&nbsp;&nbsp;$$P(\{\omega_2\}) = 0.5$$，$$P(\Omega)=1$$。  

## 事件  
###### 贝叶斯定理  
**条件概率**：事件B满足P(B)>0，事件B发生的前提下，事件A发生的概率，记作P(A|B)。  
**贝叶斯定理**：如果事件A和B同时发生，那么首先事件B必须发生，然后在事件B发生的前提下发生事件A，所以P(AB)=P(B)P(A|B)，即有贝叶斯定理:$$P(A|B)=\frac{P(AB)}{P(B)}$$。  
>应用举例：某疾病患病率0.001，医院诊断该疾病正确率为0.99，(如果患病，0.99的概率被诊断为患病，如果没患病，0.99的概率被诊断为不患病)，如果某人被诊断该疾病为阳性(患病)，这个人患病的概率为多少？
A：这个人患病，B：医院诊断为阳性，则求P(A|B)。已知P(A)=0.0001，P(B|A)=0.99，则有$$P(A|B)=\frac{P(AB)}{P(B)}=\frac{P(B|A)P(A)}{P(B|A)P(A)+P(B|A^c)P(A^c)}=0.09$$。  
也就是说，这个人患病的概率为9%，如果复查还为阳性，则可计算得患病概率为90%  

###### 事件的独立与互斥
-  独立：若P(AB)=P(A)*P(B)，则称事件A和B相互独立。
-  互斥：若P(AB)=0,则称事件A和B互斥。

## 随机变量  
X:$$\Omega\rightarrow R$$的可测函数。  
###### 随机变量定义的事件  
$$\{X(\omega)>0\}$$是$$\Omega$$的子集，也是$$\mathcal{F}$$的元素，它是一个事件，简记$$\{X>0\}$$，$$P(\{X>0\})$$记作P(X>0)。  
###### 离散型随机变量  
随机变量X只能取可数个值。  
**概率分布**：设离散型随机变量X的取值为$$x_1,x_2,\cdots,x_n,\cdots$$，则$$P(x_n)=P(X=x_n),n=1,2,\cdots$$称为X的概率分布(概率函数)。  
**期望**：$$E(X)=\sum x_iP(x_i),i=1,2,\cdots$$  
**方差**：$$D(X)=E(X-EX)=\sum (x_i-EX)^2P(x_i)=E(X^2)-(EX)^2$$  
###### 连续型随机变量  
对于随机变量X，存在一个非负函数p(x)使得$$F(x)=P(X\leq x)=\int_{-\infty}^x p(t)dt$$，称p(x)是密度函数，F(x)是分布函数。  
$$F(x_2)-F(x_1)=P(x_1\leq X\leq x_2)=\int_{x_1}^{x_2}p(t)dt$$  
**期望**：$$EX=\int_{-\infty}^{+\infty}xf(x)dx$$  
**方差**：$$DX=E(X-EX)^2=\int_{-\infty}^{+\infty}(x-EX)^2f(x)dx$$  
###### 二维随机变量  
**分布函数**：X和Y是随机变量，对任意(x,y)，二元函数$$F(x,y)=P(X\leq x and Y\leq y)=P(X\leq x,Y\leq y)$$称为二维随机变量(X,Y)的分布函数。  
**分布律**：设离散型二维随机变量(X,Y)的可能取值$$(x_i,y_i)$$，则$$P(X=x_i,Y=y_i)=p_{ij}$$称为(X,Y)的分布律。  
**联合概率密度**：对于连续型二维随机变量(X,Y)的分布函数F(x,y)，如果存在非负函数f(x,y)使得对任意x,y有$$F(x,y)=\int_{-\infty}^x \int_{-\infty}^y f(u,v)dudv$$，则f(x,y)称(X,Y)是联合密度函数。  
###### 随机变量的独立性  
- 称两个离散型随机变量X、Y相互独立，如果对(X,Y)的所有取值$$(x_i,y_i)$$，有$$P(X=x_i,Y=y_i)=P(X=x_i)P(Y=y_i)$$。
- 称两个连续型随机变量X、Y相互独立，如果对任意(x,y)，有$$f(x,y)=f_X(x)f_Y(y)$$。
其中，f(x,y)是X,Y的联合密度分布，$$f_X(x)$$和$$f_Y(y)$$是X和Y的边缘密度函数。 

## 特征函数  
随机变量X的特征函数定义为:$$\varphi_X(t)=E(e^{itX})=\int_{-\infty}^{+\infty} e^{itx}f_X(x) dx$$  
>1.两个随机变量有相同的概率分布等价物有相同的特征函数。  
2.独立随机变量和的特征函数等于每个随机变量的特征函数的积。  

## 常见的概率分布  
###### 伯努利分布  
事件发生，结果为1，不发生则结果为0。  
$$X(\omega)=\begin{cases}1,\omega属于事件A\\0,\omega不属于事件A\end{cases}$$  
其分布律为$$P(X)=\begin{cases}p,\text{X=1}\\1-p,\text{X=0}\end{cases}$$。  
**期望**：$$EX=p$$  
**方差**：$$DX=p(1-p)$$  
###### 二项分布  
二项分布即n重伯努利实验，$$\xi$$表示随机实验的结果，如果事件发生的概率为p，n次独立重复实验中，$$\xi$$表示事件发生的次数，于是$$P(\xi=k)=C_n^k p^k (1-p)^(n-k)$$。  
二项分布记作$$\xi~B(n,p)$$  
**期望**：$$E\xi=np$$  
**方差**：$$D\xi=np(1-p)$$  
B(1,p)即伯努利分布  
应用举例：在医学中阴性或者阳性、被感染源被感染或者没有被感染、生存或者死亡等。  
###### 泊松分布  
泊松分布的概率函数为$$P(X=k)=\frac{\lambda^k}{k!}e^{-\lambda},k=0,1,2...$$  
泊松分布的参数$$\lambda$$是单位时间或者单位面积内随机事件的平均发生率。泊松分布适合于描述单位事件面积内随机事件发生的次数。  
例如，电台收到的呼叫次数、站台的候客人数、机器出现故障次数、产品的缺陷数、单位区域内的细菌分布数等。P(X)表示单位时间或面积事件发生的次数。  
泊松分布的期望和方差均为$$\lambda$$，特征函数$$\varphi (t)=exp\{\lambda (e^{it}-1)\}$$  
Possion分布记作$$P(\lambda)$$  
>当二项分布的n很大p很小时，possion分布可以看作是二项分布的近似，其中$$\lambda=np$$，通常当$$n\geq 20,p\leq 0.05$$时用possion分布替代处理，事实上，possion分布是通过二项分布推倒出来的。  

###### 均匀分布  
随机变量X的密度函数为$$f(x)=\frac{1}{b-1},a<x<b$$,称X服从[a,b]上的均匀分布，记作X~U[a,b]  
**期望**：$$EX=\int_{-\infty}^{+\infty} xf(x) dx=\frac{a+b}{2}$$  
**方差**：$$DX=\int_{-\infty}^{+\infty} x^2f(x) dx=\frac{(b-a)^2}{12}$$  
**分布函数**：$$F(x)=\int_{-\infty}^{x} f(t) dt=\begin{cases}0,x<a\\ \frac{x-a}{b-a},a\leq x<b\\1,x>b \end{cases}$$  
**特征函数**：$$\varphi(x)=\frac{e^{itb}-e^{ita}}{it(b-a)} $$  
###### 正态分布  
随机变量X服从一个位置参数为$$\mu$$、尺度参数为$$\delta$$的概率分布，且密度函数为$$f(x)=\frac{1}{\sqrt{2\pi}\delta}exp\{-\frac{(x-\mu)^2}{2(\delta)^2}\}$$  
则称X服从正态分布，记作$$X~N(\mu,\delta^2)$$。  
1、f(x)关于$$x=\mu$$对称，当$$x=\mu$$达到最大值  
2、在$$x=\mu\pm\delta$$时为拐点  
3、当$$\mu=0,\delta=1$$时称X为标准正态分布，密度函数和分布函数用$$\varphi(x)和\phi(x)$$表示  
4、若$$X~N(\mu,\delta^2)$$，则$$Z=\frac{X-\mu}{\delta}~N(0,1)$$  
5、若$$X~N(\mu,\delta^2)$$，则$$P{x_1<x<x_2}=\phi(\frac{x_2-\mu}{\delta})-\phi(\frac{x_1-\mu}{\delta})$$  
6、若$$X~N(\mu,\delta^2)$$，则$$P{|X-u|<k\delta}=2\phi(k)-1\approx0.0027<0.03$$，由于小概率事件通常指概率小于5%的事件，所有认为X落在$$(\mu-3\delta,\mu+3\delta)之外的概率不会发生$$，所有区间$$(\mu-3\delta,\mu+3\delta)$$看作是X的实际可能取值区间，这称为正态分布的3$$\delta$$原则。  
7、期望为$$\mu$$，方差为$$\delta^2$$，特征函数为$$\varphi(t)=exp\{i\mu t-\frac{\delta^2t^2}{2}\}$$  
###### 指数分布  
指数分布可以用来描述随机事件发生的事件间隔，例如旅客进机场的事件间隔，百科出现新词条的事件间隔；许多电子产品的寿命分布一般服从指数分布，有些系统的寿命也可以用指数分布描述。当产品的失效是偶然失效时，其寿命服从指数分布。  
设事件单位事件内发生的次数为$$\lambda$$，如果随机变量X的密度函数为$$f(x)=\lambda e^{-\lambda x},x\geq 0$$，则称X服从指数分布，记作$$X~E(\lambda)$$。  
1、期望为$$\frac{1}{\lambda}$$，例如，如果平均每小时接2个电话，那么等待时间间隔为$$\frac{1}{2}$$。  
2、方差为$$\frac{1}{\lambda^2}$$  
3、指数分布是伽马分布的特殊情形。  
4、指数分布无记忆性。P{X>s+t|X>t}=P{X>s}，例如，某元器件已经使用了t小时，那么元器件能使用s+t小时的概率与刚开始没有使用的情况下使用s小时的概率是一样的。  
5、特征函数：$$\varphi(x)=(1-\frac{it}{\lambda})^{-1}$$  
###### $$\beta (beta)$$分布  
假设从U(0,1)中取n个数，求第k个数的分布。  
$$f(x)=lim_{\Delta x\rightarrow0}\frac{C_n^1C_{n-1}^{k-1}x^{k-1}(1-x-\Delta x)^{n-k}\Delta x}{\Delta x}=\frac{\Gamma{n+1}}{\Gamma{k}\Gamma{n-k+1}}x^{k-1}(1-x)^{n-k}$$  
如果设$$\alpha=k,\beta=n-k+1$$，则$$f(x)=\frac{\Gamma{(\alpha+\beta)}}{\Gamma{(\alpha)}\Gamma{(\beta)}}x^{\alpha-1}(1-x)^{\beta-1}=\frac{1}{B(\alpha,\beta)}x^{\alpha-1}(1-x)^{\beta-1}$$  
1、如果先验分布与后验分布属于同类，则称它们是共轭分布，先验分布被称为似然函数的共轭先验。  
2、$$P(\theta)$$是先验分布，  
$$P(\theta|X)$$是后验分布，P(X)，$$P(X|\theta) $$是似然函数。那么通过贝叶斯公式进行连接： 后验分布 = 似然函数* 先验分布/ P(X)。  
3、先验分布为beta分布，似然函数为二项分布的似然函数，得到的后验分布仍然是beta分布。所以它们共轭。  
>$$\Gamma(x)=\int_0^{+\infty}t^{x-1}e^{-t}dt$$  
$$\Gamma(x+1)=x\Gamma(x)$$  
$$\Gamma{(\frac{1}{2})}=\sqrt{\pi}$$  
$$B(\alpha,\beta)=\int_0^1x^{m-1}(1-x)^{n-1}dx=\frac{\Gamma(m)\Gamma(n)}{\Gamma(m+n)}$$  

###### $$\Gamma$$分布  
假设随机变量X为等到低$$\alpha$$件事发生所需要等待的事件，密度函数为$$f(x,\alpha,\beta)=\frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x},x>0$$  
1、当$$\beta=n$$，$$Ga(\alpha,n)$$就是Erlang分布。Erlang分布常用于可靠性理论和排队论中 ,如一个复杂系统中从第 1 次故障到恰好再出现 n 次故障所需的时间;从某一艘船到达港口直到恰好有 n 只船到达所需的时间都服从 Erlang分布；  
2、$$E(X)=\frac{\alpha}{\beta}$$，$$Var(X)=\frac{\alpha}{\beta^2}$$，特征函数$$\varphi(t)=(1-\frac{it}{\beta})^{-\alpha}$$  
3、可加性：$$r.v.X\sim Ga(\alpha_1,\lambda),r.v.Y\sim Ga(\alpha_2,\lambda) \Rightarrow X+Y\sim Ga(\alpha_1+\alpha_2,\lambda)$$  
4、$$Ga(1,\frac{1}{\lambda})$$即为$$E(\lambda)$$；$$Ga( \frac{1}{n}, \frac{1}{2})$$即为$$\chi^2(n)$$  
## 大数定律与中心极限定理  
###### 切比雪夫不等式  
对随机变量X以及任意$$\varepsilon >0$$，有$$P(|X-EX|\geq {\varepsilon}^2)\leq DX/{\varepsilon}^2$$。  
###### 切比雪夫大数定律  
设随机变量序列$$\{X_i\}$$，两两不相关，期望方差为$$\mu_i$$和$$\delta_i^2$$，方差有上界K，则有$$\lim_{n\rightarrow +\infty}\{|\frac{1}{n}\sum X_i-\frac{1}{n}\sum \mu_i|<\varepsilon\}=1$$  
###### 伯努利大数定律  
如果$$\{X_i\}$$的分布是伯努利分布，事件成功的概率为p， 如果成功$$X_i=1$$，否则为0，则通过切比雪夫大数定律得到,$$\lim_{n\rightarrow +\infty}\{|\frac{f_A}{n}-p|<\varepsilon\}=1$$，其中$$f_A$$是成功的次数。
>伯努利大数定律说明当n足够大时，事件发生的频率趋近于事件发生的概率  

###### 中心极限定理  
随机变量序列$$\{X_i\}$$相互独立，且$$EX_i=\mu$$， $$DX_i=\delta^2$$ ，则当$$n\rightarrow +\infty$$时，$$Z_n=(\sum X_i -n\mu)/\sqrt{n}\delta\rightarrow N(0,1)$$  
令$$Y_i=X_i-\mu$$，则$$Y_i$$独立同分布，且$$EY_i=0$$， $$DY_i=\delta^2$$，设$$Y_i$$特征函数为$$\varphi (t)$$ ，于是$$Z_n$$的特征函数为$$\varphi_{Z_n}(t)=[ \varphi (\frac{t}{\sqrt n\delta})]^n$$,  
$$\varphi (t)$$ 展开幂级数得$$\varphi (t)=1-\frac{\delta ^2}{2}t^2+o(t^2)$$，于是$$\varphi_{Z_n}(t)=[1-\frac{1}{2n}t^2+o(\frac {t^2}{n\delta ^2})]^n$$  
所以，当$$n\rightarrow +\infty$$时，$$\varphi_{Z_n}(t)\rightarrow e^{-t^2/2}$$，所以$$Z_n \rightarrow N(0,1)$$。  
>中心极限定理表明，任何一个容量为n的抽样样本，当n足够大时，样本的均值近似服从$$N(\mu,\delta^2/n)$$  
